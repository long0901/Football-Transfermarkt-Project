{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3750,
          "status": "ok",
          "timestamp": 1752407081054,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "cQxnhbftmb7c",
        "outputId": "c4fea73a-e6a8-4017-e93a-0fdfed2c5087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File ‘/content/jars/spark-bigquery-0.42.4.jar’ already there; not retrieving.\n",
            "--2025-07-13 11:44:38--  https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.14/gcs-connector-hadoop3-2.2.14-shaded.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38298738 (37M) [application/java-archive]\n",
            "Saving to: ‘/content/jars/gcs-connector-hadoop3-2.2.14.jar’\n",
            "\n",
            "/content/jars/gcs-c 100%[===================>]  36.52M  14.0MB/s    in 2.6s    \n",
            "\n",
            "2025-07-13 11:44:41 (14.0 MB/s) - ‘/content/jars/gcs-connector-hadoop3-2.2.14.jar’ saved [38298738/38298738]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget -nc https://repo1.maven.org/maven2/com/google/cloud/spark/spark-bigquery-with-dependencies_2.12/0.42.4/spark-bigquery-with-dependencies_2.12-0.42.4.jar \\\n",
        "     -O /content/jars/spark-bigquery-0.42.4.jar\n",
        "\n",
        "!wget -nc https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.14/gcs-connector-hadoop3-2.2.14-shaded.jar \\\n",
        "     -O /content/jars/gcs-connector-hadoop3-2.2.14.jar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5704,
          "status": "ok",
          "timestamp": 1752407111984,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "KalytEYFmlmf",
        "outputId": "2f40a0ec-cf4f-4a37-ea89-83d32d72cc1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ GCS connector: True\n",
            "✅ BigQuery jar : True\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pathlib import Path\n",
        "import os, re\n",
        "\n",
        "KEY_PATH     = \"<Your key path>\"\n",
        "DATA_BUCKET  = \"<Your data bucket>\"\n",
        "TEMP_BUCKET  = \"<Your temp bucket>\"\n",
        "PROJECT_ID   = \"<Your project id>\"\n",
        "DATASET      = \"<Your dataset>\"\n",
        "\n",
        "JAR1 = \"/content/jars/spark-bigquery-0.42.4.jar\"\n",
        "JAR2 = \"/content/jars/gcs-connector-hadoop3-2.2.14.jar\"\n",
        "ALL_JARS = \",\".join([JAR1, JAR2])\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = KEY_PATH\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "      .appName(\"Spark-GCS-BQ Full Working\")\n",
        "      .master(\"local[*]\")\n",
        "      .config(\"spark.jars\", ALL_JARS)\n",
        "      .config(\"spark.driver.extraClassPath\", ALL_JARS)\n",
        "      .config(\"spark.executor.extraClassPath\", ALL_JARS)\n",
        "\n",
        "      # ---- GCS connector ----\n",
        "      .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
        "      .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
        "      .config(\"spark.hadoop.fs.gs.project.id\", PROJECT_ID)\n",
        "      .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\n",
        "      .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", KEY_PATH)\n",
        "\n",
        "      # ---- BigQuery connector ----\n",
        "      .config(\"temporaryGcsBucket\", TEMP_BUCKET)\n",
        "\n",
        "      .getOrCreate()\n",
        ")\n",
        "\n",
        "cp = spark.sparkContext._jvm.java.lang.System.getProperty(\"java.class.path\")\n",
        "print(\"✅ GCS connector:\", \"gcs-connector\" in cp)\n",
        "print(\"✅ BigQuery jar :\", \"spark-bigquery\" in cp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FNYRp5cmxFT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 75510,
          "status": "ok",
          "timestamp": 1752407233550,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "yrF-hsimeChE"
      },
      "outputs": [],
      "source": [
        "df_appearances = spark.read.csv('gs://long09011/appearances.csv', header=True, inferSchema=True)\n",
        "df_club_games = spark.read.csv('gs://long09011/club_games.csv', header=True, inferSchema=True)\n",
        "df_clubs = spark.read.csv('gs://long09011/clubs.csv', header=True, inferSchema=True)\n",
        "df_games = spark.read.csv('gs://long09011/games.csv', header=True, inferSchema=True)\n",
        "df_competitions = spark.read.csv('gs://long09011/competitions.csv', header=True, inferSchema=True)\n",
        "df_game_lineups = spark.read.csv('gs://long09011/game_lineups.csv', header=True, inferSchema=True)\n",
        "df_player_valuations = spark.read.csv('gs://long09011/player_valuations.csv', header=True, inferSchema=True)\n",
        "df_players = spark.read.csv('gs://long09011/players.csv', header=True, inferSchema=True)\n",
        "df_transfers = spark.read.csv('gs://long09011/transfers.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1752407233550,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "O5DuS9lXemKk"
      },
      "outputs": [],
      "source": [
        "df_competitions_filtered = df_competitions \\\n",
        "    .filter(df_competitions['country_name'].isNotNull()) \\\n",
        "    .dropDuplicates(['name']) \\\n",
        "    .select('competition_id', 'name', 'type', 'country_name', 'confederation', 'is_major_national_league') \\\n",
        "    .withColumnRenamed('name', 'competition_name') \\\n",
        "    .withColumnRenamed('type', 'competition_type')\n",
        "\n",
        "\n",
        "\n",
        "df_clubs_filtered = df_clubs.join(df_competitions_filtered, df_clubs[\"domestic_competition_id\"] == df_competitions_filtered[\"competition_id\"], how=\"inner\") \\\n",
        "    .select(df_clubs['club_id'], \\\n",
        "            df_clubs['name'].alias('club_name'), \\\n",
        "            df_clubs['domestic_competition_id'], \\\n",
        "            df_clubs['stadium_name'], \\\n",
        "            df_clubs['stadium_seats'])\n",
        "\n",
        "\n",
        "\n",
        "df_clubs_home = df_clubs_filtered.alias(\"home_club\")\n",
        "df_clubs_away = df_clubs_filtered.alias(\"away_club\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 214,
          "status": "ok",
          "timestamp": 1752407233762,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "cvyT8Zl2e2Bd"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "executionInfo": {
          "elapsed": 656,
          "status": "ok",
          "timestamp": 1752407234417,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "__Rfouf5ewEV"
      },
      "outputs": [],
      "source": [
        "df_games_filtered = df_games.join(df_competitions_filtered, df_games[\"competition_id\"] == df_competitions_filtered[\"competition_id\"], how=\"inner\") \\\n",
        "    .join(df_clubs_home, df_games[\"home_club_id\"] == df_clubs_home[\"club_id\"], how=\"inner\") \\\n",
        "    .join(df_clubs_away, df_games[\"away_club_id\"] == df_clubs_away[\"club_id\"], how=\"inner\") \\\n",
        "    .select(df_games['game_id'], \\\n",
        "            df_games['competition_id'], \\\n",
        "            df_games['date'], \\\n",
        "            df_games['season'], \\\n",
        "            df_games['round'], \\\n",
        "            df_games['home_club_id'], \\\n",
        "            df_games['away_club_id'], \\\n",
        "            df_games['home_club_name'], \\\n",
        "            df_games['away_club_name'], \\\n",
        "            df_games['home_club_goals'], \\\n",
        "            df_games['away_club_goals'], \\\n",
        "            df_games['home_club_manager_name'], \\\n",
        "            df_games['away_club_manager_name'], \\\n",
        "            df_games['stadium'], \\\n",
        "            df_games['attendance'], \\\n",
        "            df_games['referee'], \\\n",
        "            df_games['competition_type'])\n",
        "\n",
        "\n",
        "\n",
        "df_club_games_filtered = df_club_games.join(df_clubs_filtered, df_club_games[\"club_id\"] == df_clubs_filtered[\"club_id\"], how=\"inner\") \\\n",
        "    .join(df_games_filtered, df_club_games[\"game_id\"] == df_games_filtered[\"game_id\"], how=\"inner\") \\\n",
        "    .select(df_club_games['game_id'], \\\n",
        "            df_club_games['club_id'], \\\n",
        "            df_club_games['own_goals'], \\\n",
        "            df_club_games['opponent_id'], \\\n",
        "            df_club_games['opponent_goals'], \\\n",
        "            df_club_games['hosting'], \\\n",
        "            df_club_games['is_win'])\n",
        "\n",
        "\n",
        "\n",
        "df_players_filtered = df_players \\\n",
        "    .join(df_clubs_filtered, df_players['current_club_id'] == df_clubs_filtered['club_id'], 'inner') \\\n",
        "    .dropDuplicates(['name']) \\\n",
        "    .select(\n",
        "        df_players['player_id'],\n",
        "        df_players['name'].alias('player_name'),\n",
        "        df_players['last_season'],\n",
        "        df_players['current_club_id'],\n",
        "        df_players['country_of_birth'],\n",
        "        df_players['country_of_citizenship'].alias('nationality'),\n",
        "        df_players['date_of_birth'].cast('date').alias('date_of_birth'),\n",
        "        (F.datediff(F.current_date(), df_players['date_of_birth'].cast('date')) / 365).cast('int').alias('age'),\n",
        "        df_players['position'],\n",
        "        df_players['foot'],\n",
        "        df_players['height_in_cm'],\n",
        "        df_players['market_value_in_eur'],\n",
        "        df_players['highest_market_value_in_eur'],\n",
        "        df_players['image_url']\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "df_player_valuations_filtered = df_player_valuations.join(df_players_filtered, df_player_valuations[\"player_id\"] == df_players_filtered[\"player_id\"], how=\"inner\") \\\n",
        "    .join(df_clubs_filtered, df_player_valuations[\"current_club_id\"] == df_clubs_filtered[\"club_id\"], how=\"inner\") \\\n",
        "    .select(df_player_valuations['player_id'], \\\n",
        "            df_player_valuations['date'], \\\n",
        "            F.year(df_player_valuations['date']).alias('season'), \\\n",
        "            df_player_valuations['market_value_in_eur'], \\\n",
        "            df_player_valuations['current_club_id'])\n",
        "\n",
        "\n",
        "df_game_lineups_filtered = df_game_lineups \\\n",
        "    .filter((df_game_lineups['date'].isNotNull()) &\n",
        "            (df_game_lineups['date'] != '0') &\n",
        "            (df_game_lineups['date'] != '1')) \\\n",
        "    .join(df_players_filtered, df_game_lineups['player_id'] == df_players_filtered['player_id'], 'inner') \\\n",
        "    .join(df_clubs_filtered, df_game_lineups['club_id'] == df_clubs_filtered['club_id'], 'inner') \\\n",
        "    .join(df_games_filtered, df_game_lineups['game_id'] == df_games_filtered['game_id'], 'inner') \\\n",
        "    .select(\n",
        "        df_game_lineups['game_lineups_id'],\n",
        "        df_game_lineups['date'].cast('date').alias('date'),\n",
        "        df_game_lineups['game_id'],\n",
        "        df_game_lineups['player_id'],\n",
        "        df_game_lineups['club_id'],\n",
        "        df_game_lineups['player_name'],\n",
        "        df_game_lineups['type'],\n",
        "        df_game_lineups['position'],\n",
        "        df_game_lineups['number'],\n",
        "        df_game_lineups['team_captain']\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "df_clubs_from = df_clubs_filtered.alias(\"from_club\")\n",
        "df_clubs_to = df_clubs_filtered.alias(\"to_club\")\n",
        "\n",
        "df_transfers_filtered = df_transfers \\\n",
        "    .filter(df_transfers['transfer_fee'].isNotNull()) \\\n",
        "    .join(df_clubs_from, df_transfers['from_club_id'] == df_clubs_from['club_id'], 'inner') \\\n",
        "    .join(df_clubs_to, df_transfers['to_club_id'] == df_clubs_to['club_id'], 'inner') \\\n",
        "    .join(df_players_filtered, df_transfers['player_id'] == df_players_filtered['player_id'], 'inner') \\\n",
        "    .select(\n",
        "        df_transfers['player_id'],\n",
        "        df_transfers['player_name'],\n",
        "        df_transfers['transfer_date'],\n",
        "        (df_transfers['transfer_season'].substr(1, 2).cast('int') + 2000).alias('season'),\n",
        "        df_transfers['from_club_id'],\n",
        "        df_transfers['to_club_id'],\n",
        "        df_transfers['transfer_fee'],\n",
        "        df_transfers['market_value_in_eur']\n",
        "    )\n",
        "\n",
        "df_appearances_filtered = df_appearances \\\n",
        "    .filter(df_appearances['player_name'].isNotNull()) \\\n",
        "    .join(df_competitions_filtered, df_appearances['competition_id'] == df_competitions_filtered['competition_id'], 'inner') \\\n",
        "    .join(df_clubs_filtered, df_appearances['player_club_id'] == df_clubs_filtered['club_id'], 'inner') \\\n",
        "    .join(df_games_filtered, df_appearances['game_id'] == df_games_filtered['game_id'], 'inner') \\\n",
        "    .join(df_players_filtered, df_appearances['player_id'] == df_players_filtered['player_id'], 'inner') \\\n",
        "    .select(df_appearances['*'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 17467,
          "status": "ok",
          "timestamp": 1752407269175,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "U8p3UOWMe6YK",
        "outputId": "00b0a0b2-e3f2-4ef0-a150-408b600dbece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clubs_filtered count: 405\n",
            "appearances_filtered count: 1403183\n"
          ]
        }
      ],
      "source": [
        "print('clubs_filtered count:', df_clubs_filtered.count())\n",
        "print('appearances_filtered count:', df_appearances_filtered.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {
          "elapsed": 159341,
          "status": "ok",
          "timestamp": 1752407429753,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -420
        },
        "id": "tVuLmPs6flNQ"
      },
      "outputs": [],
      "source": [
        "df_clubs_filtered.write.format('bigquery').option('table', 'football-465805.test.clubs').mode('overwrite').save()\n",
        "df_appearances_filtered.write.format('bigquery').option('table', 'football-465805.test.appearances').mode('overwrite').save()\n",
        "df_club_games_filtered.write.format('bigquery').option('table', 'football-465805.test.club_games').mode('overwrite').save()\n",
        "df_games_filtered.write.format('bigquery').option('table', 'football-465805.test.games').mode('overwrite').save()\n",
        "df_competitions_filtered.write.format('bigquery').option('table', 'football-465805.test.competitions').mode('overwrite').save()\n",
        "df_game_lineups_filtered.write.format('bigquery').option('table', 'football-465805.test.game_lineups').mode('overwrite').save()\n",
        "df_player_valuations_filtered.write.format('bigquery').option('table', 'football-465805.test.player_valuations').mode('overwrite').save()\n",
        "df_players_filtered.write.format('bigquery').option('table', 'football-465805.test.players').mode('overwrite').save()\n",
        "df_transfers_filtered.write.format('bigquery').option('table', 'football-465805.test.transfers').mode('overwrite').save()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "name": "Demo Spark notebook",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
